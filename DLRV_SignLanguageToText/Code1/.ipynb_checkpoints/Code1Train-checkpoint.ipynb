{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Guideline: https://www.digitalocean.com/community/tutorials/how-to-build-a-neural-network-to-translate-sign-language-into-english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4592,
     "status": "ok",
     "timestamp": 1640757433202,
     "user": {
      "displayName": "Elanton Fernandes",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699911654483663236"
     },
     "user_tz": -60
    },
    "id": "LACClcYzw0tG",
    "outputId": "f17585c5-ac82-4632-8d9b-d68c5cbe86aa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://assets.digitalocean.com/articles/signlanguage_data/sign-language-mnist.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1290,
     "status": "ok",
     "timestamp": 1640757486950,
     "user": {
      "displayName": "Elanton Fernandes",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699911654483663236"
     },
     "user_tz": -60
    },
    "id": "cE5Zd-D5w30Q",
    "outputId": "0fbd1ae9-63cc-4e10-ab4b-dc58fbf50d4a"
   },
   "outputs": [],
   "source": [
    "!tar -xzf sign-language-mnist.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bj-jLjuXxE1Y"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import csv\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bj-jLjuXxE1Y"
   },
   "outputs": [],
   "source": [
    "class SignLanguageMNIST(Dataset):\n",
    "    \"\"\"Sign Language classification dataset.\n",
    "    Utility for loading Sign Language dataset into PyTorch. Dataset posted on\n",
    "    Kaggle in 2017, by an unnamed author with username `tecperson`:\n",
    "    https://www.kaggle.com/datamunge/sign-language-mnist\n",
    "    Each sample is 1 x 1 x 28 x 28, and each label is a scalar.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_mapping():\n",
    "        \"\"\"\n",
    "        We map all labels to [0, 23]. This mapping from dataset labels [0, 23]\n",
    "        to letter indices [0, 25] is returned below.\n",
    "        \"\"\"\n",
    "        mapping = list(range(25))\n",
    "        mapping.pop(9)\n",
    "        return mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def read_label_samples_from_csv(path: str):\n",
    "        \"\"\"\n",
    "        Assumes first column in CSV is the label and subsequent 28^2 values\n",
    "        are image pixel values 0-255.\n",
    "        \"\"\"\n",
    "        mapping = SignLanguageMNIST.get_label_mapping()\n",
    "        labels, samples = [], []\n",
    "        with open(path) as f:\n",
    "            _ = next(f)  # skip header\n",
    "            for line in csv.reader(f):\n",
    "                label = int(line[0])\n",
    "                labels.append(mapping.index(label))\n",
    "                samples.append(list(map(int, line[1:])))\n",
    "        return labels, samples\n",
    "\n",
    "    def __init__(self,\n",
    "            path: str=\"data/sign_mnist_train.csv\",\n",
    "            mean: List[float]=[0.485],\n",
    "            std: List[float]=[0.229]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...\n",
    "        \"\"\"\n",
    "        labels, samples = SignLanguageMNIST.read_label_samples_from_csv(path)\n",
    "        self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 28, 28, 1))\n",
    "        self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))\n",
    "\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(28, scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self._mean, std=self._std)])\n",
    "\n",
    "        return {\n",
    "            'image': transform(self._samples[idx]).float(),\n",
    "            'label': torch.from_numpy(self._labels[idx]).float()\n",
    "        }\n",
    "    \n",
    "class SignLanguageCollected(Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_mapping():\n",
    "        mapping = list(range(26))\n",
    "        return mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def read_label_samples_from_csv(path: str):\n",
    "        \"\"\"\n",
    "        Assumes first column in CSV is the label and subsequent 28^2 values\n",
    "        are image pixel values 0-255.\n",
    "        \"\"\"\n",
    "        mapping = SignLanguageCollected.get_label_mapping()\n",
    "        labels, samples = [], []\n",
    "        with open(path) as f:\n",
    "            _ = next(f)  # skip header\n",
    "            for line in csv.reader(f):\n",
    "                label = int(line[0])\n",
    "                labels.append(mapping.index(label))\n",
    "                samples.append(list(map(int, line[1:])))\n",
    "        return labels, samples\n",
    "\n",
    "    def __init__(self,\n",
    "            path: str=\"../Data/collected_train.csv\",\n",
    "            mean: List[float]=[0.485],\n",
    "            std: List[float]=[0.229]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...\n",
    "        \"\"\"\n",
    "        labels, samples = SignLanguageCollected.read_label_samples_from_csv(path)\n",
    "        self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 28, 28, 1))\n",
    "        self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))\n",
    "\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomResizedCrop(28, scale=(0.8, 1.2)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self._mean, std=self._std)])\n",
    "\n",
    "        return {\n",
    "            'image': transform(self._samples[idx]).float(),\n",
    "            'label': torch.from_numpy(self._labels[idx]).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9430,
     "status": "ok",
     "timestamp": 1640758886648,
     "user": {
      "displayName": "Elanton Fernandes",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699911654483663236"
     },
     "user_tz": -60
    },
    "id": "IaqLciVd2YPF",
    "outputId": "08cf6fd5-ee63-4218-e1de-0308b76937e0"
   },
   "outputs": [],
   "source": [
    "def get_train_test_loaders(use_mnist_dataset,batch_size=32):\n",
    "    \n",
    "    if(use_mnist_dataset):\n",
    "        print(\"Using kaggle get_train_test_loader\")\n",
    "        trainset = SignLanguageMNIST('data/sign_mnist_train.csv')\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        testset = SignLanguageMNIST('data/sign_mnist_test.csv')\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        print(\"Using collected get_train_test_loader\")\n",
    "        trainset = SignLanguageCollected('../Data/collected_train.csv')\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        testset = SignLanguageCollected('../Data/collected_test.csv')\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loader, _ = get_train_test_loaders(True,2)\n",
    "    print(next(iter(loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-Pk7Y_GxX9K"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 266562,
     "status": "ok",
     "timestamp": 1640759162015,
     "user": {
      "displayName": "Elanton Fernandes",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699911654483663236"
     },
     "user_tz": -60
    },
    "id": "2bF11Lecx7JT",
    "outputId": "d75213ac-853e-4dd1-fcff-c831aea36945",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,use_mnist_dataset):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 6, 3)\n",
    "        self.conv3 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 48)\n",
    "        if(use_mnist_dataset):\n",
    "            self.fc3 = nn.Linear(48, 24)\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(48, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def main(use_mnist_dataset,checkpoint_name):\n",
    "    if(use_mnist_dataset):\n",
    "        net = Net(use_mnist_dataset).float()\n",
    "    else:\n",
    "        net = Net(use_mnist_dataset).float()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    trainloader, testloader = get_train_test_loaders(use_mnist_dataset=use_mnist_dataset)\n",
    "    for epoch in range(12):  # loop over the dataset multiple times\n",
    "        train(net, criterion, optimizer, trainloader, epoch)\n",
    "        scheduler.step()\n",
    "    torch.save(net.state_dict(), checkpoint_name)\n",
    "\n",
    "\n",
    "def train(net, criterion, optimizer, trainloader, epoch):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs = Variable(data['image'].float())\n",
    "        labels = Variable(data['label'].long())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels[:, 0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 0:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch, i, running_loss / (i + 1)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69405,
     "status": "ok",
     "timestamp": 1640759974892,
     "user": {
      "displayName": "Elanton Fernandes",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06699911654483663236"
     },
     "user_tz": -60
    },
    "id": "qcPuJ-XkyVxt",
    "outputId": "6b02251e-4511-4069-a1d9-e63f668a410b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate(outputs: Variable, labels: Variable) -> float:\n",
    "    \"\"\"Evaluate neural network outputs against non-one-hotted labels.\"\"\"\n",
    "    Y = labels.numpy()\n",
    "    Yhat = np.argmax(outputs, axis=1)\n",
    "    return float(np.sum(Yhat == Y))\n",
    "\n",
    "\n",
    "def batch_evaluate(\n",
    "        net: Net,\n",
    "        dataloader: torch.utils.data.DataLoader) -> float:\n",
    "    \"\"\"Evaluate neural network in batches, if dataset is too large.\"\"\"\n",
    "    score = n = 0.0\n",
    "    for batch in dataloader:\n",
    "        n += len(batch['image'])\n",
    "        outputs = net(batch['image'])\n",
    "        if isinstance(outputs, torch.Tensor):\n",
    "            outputs = outputs.detach().numpy()\n",
    "        score += evaluate(outputs, batch['label'][:, 0])\n",
    "    return score / n\n",
    "\n",
    "\n",
    "def validate(checkpoint_name,filename,use_mnist_dataset):\n",
    "    trainloader, testloader = get_train_test_loaders(use_mnist_dataset=use_mnist_dataset)\n",
    "    if(use_mnist_dataset):\n",
    "        net = Net(use_mnist_dataset).float().eval()\n",
    "    else:\n",
    "        net = Net(use_mnist_dataset).float().eval()\n",
    "\n",
    "    pretrained_model = torch.load(checkpoint_name)\n",
    "    net.load_state_dict(pretrained_model)\n",
    "\n",
    "    print('=' * 10, 'PyTorch', '=' * 10)\n",
    "    train_acc = batch_evaluate(net, trainloader) * 100.\n",
    "    print('Training accuracy: %.1f' % train_acc)\n",
    "    test_acc = batch_evaluate(net, testloader) * 100.\n",
    "    print('Validation accuracy: %.1f' % test_acc)\n",
    "\n",
    "    trainloader, testloader = get_train_test_loaders(use_mnist_dataset=use_mnist_dataset,batch_size=1)\n",
    "\n",
    "    # export to onnx\n",
    "    fname = filename\n",
    "    dummy = torch.randn(1, 1, 28, 28)\n",
    "    torch.onnx.export(net, dummy, fname, input_names=['input'])\n",
    "\n",
    "    # check exported model\n",
    "    model = onnx.load(fname)\n",
    "    onnx.checker.check_model(model)  # check model is well-formed\n",
    "\n",
    "    # create runnable session with exported model\n",
    "    ort_session = ort.InferenceSession(fname)\n",
    "    net = lambda inp: ort_session.run(None, {'input': inp.data.numpy()})[0]\n",
    "\n",
    "    print('=' * 10, 'ONNX', '=' * 10)\n",
    "    train_acc = batch_evaluate(net, trainloader) * 100.\n",
    "    print('Training accuracy: %.1f' % train_acc)\n",
    "    test_acc = batch_evaluate(net, testloader) * 100.\n",
    "    print('Validation accuracy: %.1f' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    USE_MNIST_DATASET = True\n",
    "    \n",
    "    if (USE_MNIST_DATASET):\n",
    "        main(use_mnist_dataset=USE_MNIST_DATASET,checkpoint_name=\"checkpoint_kaggle.pth\")\n",
    "        validate(checkpoint_name = \"checkpoint_kaggle.pth\",filename=\"signlanguage_kaggle.onnx\",use_mnist_dataset=USE_MNIST_DATASET)\n",
    "    else:\n",
    "        main(use_mnist_dataset=USE_MNIST_DATASET,checkpoint_name=\"checkpoint_collected.pth\")\n",
    "        validate(checkpoint_name = \"checkpoint_collected.pth\",filename=\"signlanguage_collected.onnx\",use_mnist_dataset=USE_MNIST_DATASET)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3S2+T3hYd8Ir04quJsqVk",
   "name": "SignlanguageToText",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
